先来读一下ch8的文档然后回顾一下QAQ

# 读文档

## 引言

暂时没什么问题。

## 用户态线程管理

这里讲了一下green thread，但不算特别清楚，我们也许可以自己写一个更简单的版本。

另一个问题是：green thread有没有必要放在这里也是个值得商榷的问题。

## 内核态线程管理

讲的貌似比较全面，但总感觉少一些东西。

比如`thread_create`没有提到可以传参区分不同线程的问题。

## 锁机制

为什么需要锁：背景是多线程共享数据协作，由于内核调度/中断导致出现数据竞争/race condition，或者叫什么失去同步？

锁的基本思路：忙等和睡眠锁好像不太好说成是两种不同的锁机制？这里提到要关注锁的不同属性：互斥、公平和性能

> 经典四条规则：空闲则入、忙则等待（互斥）、有限等待（公平，至少避免饥饿）、让权等待（此处权指的是CPU使用权，阻塞）
>
> 这里另有一个问题：就是到底阻塞是指什么？

1. 用户态软件级实现：直接while一个单变量是不行的，于是直接过渡到双进程的Peterson算法，好像跨度有点大。后面可以拓展到多进程的Dekkers和Eisenberg算法（这个测例里面有）。这些算法在现代处理器架构下还成立吗？显然需要考虑到访存模型。
2. 机器指令硬件级
   * 关中断：保证临界区内不会被调度。缺点：过度放权给应用。而且多核情况下不适用。
   * 基于原子指令：这里介绍了不同架构提供的原子指令，如CAS/TAS以及RV上面的AMO和LR/SC指令，利用它们实现自旋锁。然而问题在于如果在用户态仅使用这个的话可能会由于忙等而浪费CPU时间。内核由于拥有更多的信息可以通过阻塞来提高总体效率。比如`futex`系统调用。（这里没有提到内存一致性模型和内存顺序，有必要吗？）
3. 内核态操作系统级
   * 为了解决上面提到到浪费CPU时间忙等的问题，可以使用`_yield`甚至`sleep`，但会导致执行延后甚至饥饿
   * 然后这一小节提到了一个`MutexBlocking`，还没介绍最关键的`block_current_and_run_next`

本章所有同步原语自身操作能够保证原子性的原因：单核，于是同时只有一个线程在系统调用

单内存位置：原子变量；多内存位置：以原子变量为标志，附加内存一致性模型

## 信号量机制

关于0的一些判定条件似乎有些问题。而且很多说法不严谨，需要重置。

信号量两段伪代码有什么区别？

基于信号量实现同步。

## 条件变量机制

开头的例子好像说明还不是很充分。

## 并发中的问题

这里面列举了三种问题：

* 互斥缺陷：指对于共享变量没有加锁
* 同步缺陷（违反顺序缺陷）：需要使用信号量等同步原语限制线程的执行依赖关系
* 死锁缺陷：死锁产生的必要条件/死锁避免/银行家算法

# 读 OSTEP 的并发部分

## 26 introduction

每个程序可以有多个执行点（point of execution）

线程间的上下文切换不必切换地址空间，然而仍然需要保存和恢复一些内容

每个线程都有自己独立的栈，引入TLS概念（然而，堆仍然是共享的，而且栈之间可能会冲突，尽管不太可能）

为什么使用线程：首先是可能充分利用多核获得更好的并行度；其次是不必整个程序完全放弃CPU使用权等待I/O，在I/O没有准备好的时候可以做一些其他的事情。这些使用多进程架构也可以达成，然而使用线程协作会更加自然，共享数据的性能更高（相比进程间通信）。

> 锁：我觉得更偏向于逻辑意义上。
>
> 锁的粒度：决定最大可能的并行度，也就决定总体效率。
>
> 万物起源于RAM，至少在当下的冯诺依曼架构之下。
>
> 对于数据竞争，需要有一个仲裁者。这可以是CPU和RAM之间的总线，也可以是某层软件。
>
> 先假定单核、简单访存模型（如何简单？），然后再尝试拓展到多核+多级缓存复杂微体系结构，这二者之间需要区分，但是本章不一定需要过多涉及多核。
>
> 就并发这一节来说，可以介绍在我们简单系统中的并发以及真实多核环境下的并发（比如常用的Rust高性能并发库`crossbeam`）。
>
> 为了实现原子化：可以依赖于硬件提供的特殊指令、操作系统内核支持、某些纯软件算法或者它们的组合。当然，每种做法涉及到不同的取舍...严格来说分析起来也许并不容易。
>
> 内核为什么是并发程序？事实上在第三章任务切换的时候就已经能够看到了。为什么引入`UPSafeCell`?
>
> 内核态并发和用户态并发的不同点：用户态并发可以有内核的支持！
>
> 无论是单核还是多核，**交错**是比访存模型更应该强调的内容，即使前者假定访存模型为最为严格的顺序一致性仍有一些问题需要注意。
>
> 提高并发度意味着放宽执行限制条件，这样正确性更难以保证，但是有可能达到更高的性能。
>
> 一个我经常喜欢说的：串行化
>
> 问题是：线程并发时的互斥需求，也就是不允许两个线程同时处于某个共享数据结构的临界区之内（这里还是需要将线程看成静态的状态机，每执行一条指令视为一次状态转移），如何满足这样的互斥需求？就是需要想办法让所有的临界区原子化，也可以说是在逻辑上将它们串行化（也许不一定正确的形象描述：两队并作一队）。
>
> 这样一种很自然的做法是：进入临界区的时候打上一个标记，表明已经有线程在临界区之内了，然后离开临界区的时候将标记清除。注意这个标记本身也属于共享数据。对于单标记的情形，使用普通的访存指令就不行了，我们需要转而使用原子指令。然而我们还可以使用多标记，可以不用借助原子指令也能够保证正确，然而其正确性不容易看出，总体也更为复杂。
>
> 所以，从总体顺序上看来，我们应该先讲解纯软件做法，然后过渡到基于原子指令比较简单的做法。
>
> 但是，只要引入原子指令，就不可避免的涉及到内存顺序。所以这里面我们再回顾一下吧。
>
> 顺序就是指：能够读到最近一次写入的值。顺序一致性模型（这家伙严格定义比较绕，我也不知道是否等价于下面的说法）显然能够满足这样的要求，它的本质是总线将所有的访存操作串行化。如果考虑到缓存的存在，那么即使单个内存位置也不容易了。于是这个时候我们可能会使用诸如MESI这样的缓存一致性协议（cache coherence protocol）。回顾一下“读到最近一次写入的值”，就会有一个问题，假如一个核写入了一个值，在一段极短时间之后另一个核读这个值，那么另一个核是读不到这个值的，因为这段时间可能不足以完成共享缓存上的一次通信。
>
> 每个核会看到一个顺序，但是不同的核看到的顺序不一定一致。
>
> 普通的访存指令相对来说比较随波逐流，就是在当前时间点看到什么就是什么。原子指令的话，除了一条指令浓缩多阶段操作的话，如果使用Relaxed顺序的话，就基本也是随波逐流。
>
> 考虑一下TSO允许违反W->R（这里的约束是指单线程上的吗？因为多线程之间本来是没有顺序的）。需要注意到在多级缓存、多核且存在缓存一致性协议的情况下，每次读写都可能很复杂。对于后面的acquire-release语义的话，...
>
> 一条重要支线：从程序员编写代码到最终执行之间，在顺序上带来的差距：首先编译器会进行优化，可能调整指令的先后顺序；处理器也可能多发射+乱序执行，虽然最后还是顺序提交，但是访存请求可能是乱序提交的（这一点可能有点口胡）。如果是编写应用的程序员的话，可能还需要考虑到操作系统的调度。这些因素都可能使得最后的执行结果与我们的预期不相符，因此我们可能要手动加上一些限制来精确描述我们期望的行为。
>
> [C++这里](https://en.cppreference.com/w/cpp/atomic/memory_order)讲的比较清楚（以后看这个就行了！），可能在编程语言这边相比ISA确实要容易一些。我们不太需要考虑标准库和指令如何配合实现编程语言规范，也许在某些ISA上原生支持，其他ISA上就没那么容易。但总体来讲我觉得规范应该还是尽可能贴近大多数主流ISA的。注意比如acquire和release或者更加严格的语义，约束是分成当前线程和线程之间两部分的。
>
> 在这样的基础上，重新考虑Rust的无畏并发：`Send`和`Sync`。

`thread_create`和`thread_join`的例子说明其中一种不确定性来源：内核调度器（包括线程创建和线程调度）。

让线程变得更加糟糕、难以使用的另一个原因：共享数据。

经典例子：两个线程多次修改一个全局计数器。

结果不确定|反汇编|这里只是考虑到时钟中断以及对应的调度，也强调即使多个线程都使用相同的寄存器也不会引起冲突

注意这个时候我们其实仍然假定这是一个单核、简单访存模型，于是看起来能够影响我们的只有时钟中断和调度了。

借由这个例子引入了数据竞争、竞态条件、临界区还有互斥的概念。

然后是引入了一个原子操作的插曲，简单来说就是"all or nothing"，它在计算机体系结构、并发代码、文件系统、数据库系统、分布式系统这些系统软件中都有十分广泛的应用。特别是在数据库的语义中，将一组操作原子化之后称为一个事务。在这本教材关于并发的内容中，仅会使用同步原语将短小的指令序列转化为原子块。但实践中原子性的内涵远不止于此。比如write-ahead log来避免文件系统操作过程中的失败。

那么如何得到我们期望的原子性呢？使用原子指令可以对同内存位置的简单访存命令的组合原子化。但是对于多内存位置的复杂数据结构的操作在多线程环境下也需要原子化。硬件不可能为每一种可能的操作都提供一条对应的指令。于是，实践中硬件提供一组比较通用的指令，我们基于它们构建常用的同步原语，进而为我们的数据结构实现定制化的原子化。注意这里可能还涉及到操作系统的介入。

多线程在访问共享数据的时候需要做到互斥，然而还有另一种常见的需求：即约束线程之间的执行顺序。比如在某个时刻线程A必须等待线程B达成了某条件之后才能继续执行下去。这样的话我们可以将线程并发执行涉及到的同步和互斥两个需求统称为同步互斥，事实上它们也经常会存在交叉。

概念：

* 临界区是指访问线程间共享资源的代码片段。
* 数据竞争、竞态条件是指多个线程同时（？）进入临界区，它们都尝试与共享资源交互，导致不正确的结果。
* 为了避免这些问题，需要引入互斥原语。

为什么要在OS课程中讨论并发？首先是历史原因，**内核是最早的并发程序**，为了使内核正确运行需要用到很多并发技巧。后面多线程程序也需要用到同样的技巧（不同的一点是这一次我们可以有操作系统的支持了！）有一个比喻也许很好：内核就像一个庞大无比的数据库，每一次中断相当于一次增删改查。

## 27 thread API

这里面主要提到了：

* `pthread_create`

* `pthread_join`

* `pthread_mutex_lock`

* `pthread_mutex_unlock`

* `pthread_mutex_init`

* `pthread_mutex_trylock`当锁已被持有时返回错误

* `pthread_mutex_timedlock`尝试获取锁，存在超时设置

* `pthread_cond_wait`注意参数中带有一个互斥锁的指针

* `pthread_cond_signal`

## 28 locks

尝试使用不同的方式构建互斥锁。

首先给出了锁的定义：这是一个变量，记录当前是否有线程在临界区中。然后有两个操作：`lock`和`unlock`。

可以直接使用pthread提供的互斥锁，然而在保护复杂的数据结构的时候需要考虑到锁的粒度。

锁的构建依赖于：硬件和OS支持。

评估锁：互斥、公平性和性能。

尝试1：关中断。

尝试2：普通访存，单flag，自旋。

尝试3：原子访存（分别基于test-and-set/CAS/LL/SC原语），单flag，自旋。

顺带一提：纯软件算法（如Peterson算法和Dekker's算法）不如提供一点硬件支持简单，而且**无法用在现代体系结构的松散一致性模型上**（这个我倒未曾考虑到，或者说应该可以用，只是效率比不上直接用硬件原语）。

三个维度评估尝试3。

尝试4：原子访存（基于fetch-and-add原语）构建ticket-lock，...保证公平性。

如何减少自旋消耗的CPU时间？（顺带一提：不使用自旋的另一个原因是为了避免优先级反转，解决方案可以使用优先级继承）

方案1：获取失败之后直接yield，上下文切换开销可能过大，而且并未解决饥饿的问题。

方案2：阻塞（也许不一定需要OS支持？不过书里提到需要OS支持，先这样吧）

最后提到了Linux中的`futex`系统调用。

## 后面的等写到后面的时候再看，重点显然是locks这一节

# 第八章代码变更

* `config.rs`里面新增了一个`MEMORY_END`
* `lang_item.rs`里面引用了新增的`current_kstack_top`，新增了panic时候的`backtrace`
* `mm/memory_set.rs`中`from_elf`的时候不再对用户栈进行映射了
* 新增`sync/condvar.rs`(我的建议是将里面的`wait`接口改成`wait_with_mutex`之类的，好像也不一定？)
* `sync/mod.rs`相应修改
* `sync/mutex.rs`新增两种互斥锁实现`MutexBlocking`和`MutexSpin`
* `sync/semaphore.rs`新增信号量实现
* `syscall/fs.rs`从`current_task`变成`current_process`
* `syscall/mod.rs`将sleep变成一个系统调用，然后新增了第八章的系统调用
* `syscall/process.rs`相关系统调用：`getpid`,`fork`,`exec`,`waitpid`,`kill`，大多数都是比较普通的修改
* `syscall/sync.rs`新增同步互斥相关系统调用的实现
* `syscall/thread.rs`新增线程相关系统调用的实现
* `task/id.rs`可以认为是每个线程的资源
* `task/manager.rs`有一些可能比较微妙的修改，还不好说
* `task/mod.rs`最重要的是新增了`block_current_and_run_next`，修改了`exit_current_and_run_next`的逻辑，还有一个`remove_inactive_task`是及时在退出一个进程的时候销毁所有阻塞的线程，这个实现还不完善，可能也还没有在后面章节使用
* `task/pid.rs`被`task/id.rs`代替了
* 对于进程而言，`task/process.rs`代替了原先的`task/task.rs`（这个现在归到线程那里了），以前进程的那些经典接口还是要保留的
* `task/processor.rs`里面应该也是进行一些相关改动
* `timer.rs`使用条件变量优化sleep系统调用
* `trap/mod.rs`中，在`trap_return`中，每个线程在所属进程地址空间中有自己独立的Trap上下文了
* 第八章线程提前退出独有的测例`early_exit`还有`early_exit2`
* 探索互斥锁实现相关测例：`race_adder`,`race_adder_arg`（这个传入的参数其实有问题），`race_adder_atomic`,`race_adder_loop`,
* 软件方法实现互斥锁测例：`peterson`和`eisenberg`
* 互斥锁测例：哲学家问题`phil_din_mutex`，`race_adder_mutex_blocking`,`race_adder_mutex_spin`
* 信号量相关测例：mpsc问题`mpsc_sem`，
* 有栈、无栈协程相关测例

# 内核级线程管理

## 代码变更

``task/id.rs``: 涉及两个分配器，PID 分配器和内核栈分配器，内核会为每个线程分配一个内核栈。内核栈有一个ID，其在内核地址空间中的地址根据此ID来计算。分配之后RAII的资源有`PidHandle`（这个在PCB中），`KernelStack`（这个在TCB中），还有一个`TaskUserRes`，其中包括一个`tid`，一个应该是从`tid`算出来的`ustack_base`，一个所属进程的弱引用。看了当时的实现发现这个并不是创建之后就直接分配内存的。分配的资源就是在进程地址空间里面映射Trap上下文和用户栈。每个进程还有一个TID分配器，不过名字叫做`task_res_allocator`了。

`task/id.rs`是代替原先的`task/pid.rs`。原先的话是直接弄了一个`PidAllocator`，`PidHandle`也是之前就有的，`KernelStack`也是之前就有的。

这个好像应该是最主要的变化了。

主要数据结构的变更：

`TaskControlBlock`从进程控制块变成线程控制块，另一种说法是调度的单位——任务从进程变成了线程。

新增了进程控制块`ProcessControlBlock`。

任务管理器`TaskManager`调整了一些相关的接口，然后就是新增了early exit相关的内容。

处理器管理结构`Processor`好像没什么变化。

这样的话我们可以尝试从几个不同的角度依次说明：

* 数据结构设计、内存布局
* 进程接口变更
* 新增的线程接口

需要注意，我们规定进程和线程接口是不相容的，不然会导致UB。

# 锁机制

线程共享数据（全局变量进行协作）

引入互斥锁，上锁-临界区-解锁

互斥锁的多种不同实现

尝试一下直接上裸的peterson，本机上结果会错误，tutorial上还可能会死循环？但是这不应该啊，tutorial是单核，那么可能

观察一下的话，busy-loop里面不加上sleep会卡死，这就很奇怪？

缩小临界区为A=A+1也会寄。而且不是整个系统卡死，有时钟中断的。

按照我们之前的思路，从汇编层面看一下。

`lock`的时候不用`volatile_read`还是不行的，会直接弄出来一个死循环。这好像是个挺不自然的bug，因为既然是static mut没有理由只考虑单线程的，好像还是rv架构限定的。

有的时候会陷入到这样的互等怪圈：

```
[1] iter=1950
[0] iter=1890
[1] iter=1960
[0] iter=1900
[1] iter=1970
[0] iter=1910
[1] iter=1980
[0] iter=1920
[1] iter=1990
```

这个时候就会特别慢。

我觉得在QEMU单核上应该是顺序一致的。但是在host多核上，就完全没那么简单了。

看了一下peterson的wikipedia，跟我的想法还是蛮一致的。

那么怎么评估peterson呢？根据wikipedia上的说法，要分成mutual exclusion,progress还有bounded waiting三个维度，应该对应到操作系统课上讲的忙则等待，空闲则入和有界等待。

从指令层面需要把lock分成5个步骤：

```
    STORE flag[id], 1
    STORE turn, 1-id
LABEL:
    LOAD reg0, flag[1-id]
    LOAD reg1, turn
    // 中间省略若干寄存器运算
	条件跳转 LABEL
```

unlock的话，就是直接 `STORE flag[id], 0`

为什么总感觉并不是很显然的事情。

如果两个lock完全分离的话，比如t0如果已经进入临界区，此时必然满足flag[0]=true，这个时候t1开始进，就肯定进不来了，因为flag[0]=true，而且turn会被t1改成0，正好卡死在循环里面

我觉得还是应该站在LOAD的主视角，确实读是比写更重要的，**只有被读到的写入才有价值**

试了一下Dekkers，好像不能yield？不yield好像也有问题。尝试加了一些compiler fence之后也还是不行，不是重点，暂时弃疗了。

空闲则入和progress基本上一个意思，但是说空闲则入的英文为progress有些不恰当

评价peterson是否满足空闲则入：不应该用调度产生的极端例子来作为反例，借此说明不满足

---

剩下的假如绕过内存顺序的话就很简单了...大概就分成两个点，基于硬件支持和OS支持实现锁机制。

* 基于硬件支持
  * 不能让应用拥有中断控制权
  * 原子指令：原版是介绍了其他平台（指x86和SPARC）上的CAS和TAS指令，以及rv平台上的AMO和LR/SC指令，那我们？？？
* 基于OS支持实现锁机制（可能需要重构desu）
  * 忙等的效率差距以及不稳定性是需要讲到的
  * 如果要说能有什么支持的话，就是让权等待了，第一个是yield
  * 第二是阻塞，除了阻塞的锁实现之外，还有sleep
  * 对了，还要强调系统调用的特殊性，在单核平台下，当前实现中，系统调用是**不可打断**的，因此无需使用互斥手段

# 纯软件锁实现的局限性及内存顺序

这个准备单独拎出来到一个附录中，不然篇幅太长了...大概先列一下提纲看看。

首先内存操作是可能乱序的。一个来源是编译器，可以考虑使用`compiler_fence`进行约束。另一个来源则是硬件执行。

（程序顺序，也就是 program order 如何定义？我觉得可能是程序员认为的，从源代码中直接翻译得到的访存顺序）

第一种模型：单核，不考虑cache，总是前面的完成之后再开始下一个。按照这种逻辑可以推及多核，不同核之间交错就行了。

但是考虑到cache？我觉得既然有现成的资料还是先学习一下吧。

# 原子指令

看起来都是read-modify-write这种，只不过LR/SC和CAS/TAS是有可能失败的，像AMO系列指令则是必定成功的。

# 内核级的锁实现

在等待一个事件的时候，如果暂时无法继续...应该，如何做？

1. 忙等
2. 使用yield暂时交出CPU使用权
3. 阻塞，彻底交出CPU使用权，直到被唤醒

（这里有什么地方比较像访问外设时候的轮询和中断的关系？轮询浪费CPU资源但是实时性更好。中断更复杂，...这样说起来的话，阻塞和中断挺像的，而yield看起来是二者的一种折衷，也是比较通用的一种思路）

调度不是只有内核态能做，同时也并不是在内核态做就一定能取得更好的效果

然后`MutexBlocking`和`MutexSpin`？本质上，是在单核上利用天生的中断屏蔽保证其自身的互斥性。

`MutexSpin`->`MutexBlocking`->阻塞的其他应用以及线程注销的相关处理

阻塞：严格来说，阻塞是一种等待事件到来的状态，在这种状态下...

多种不同的锁实现，`Mutex` Trait；锁是进程内的一种资源，一个进程内可能有多把锁

# 条件变量和信号量[学]

在介绍条件变量的时候是否有必要提到管程？管程只是条件变量的一种应用，还是说二者自诞生之日就有很紧密的联系？

在管程中也涉及到阻塞和唤醒机制。然而在实际唤醒的时候有不同的调度策略，只要是从相关线程执行的优先级上面来考虑的。假设T2要唤醒T1，此时还有其他线程：

* Hoare的话，优先级T1>T2>其他线程
* Hensen的话，优先级T2>T1>其他线程
* Mesa的话，优先级T2>T1=其他线程

这样就更好理解了。

如果阻塞语句（还是什么语句？）被包裹在一个循环中，那么被唤醒之后就需要重新竞争锁，这种是Mesa风格；如果被唤醒之后就一定能直接往下走，此时就要求唤醒者能够将锁移交过来，这种钦定的是Hoare/Hensen风格。（是否只限定单核？）如果下一个进入临界区的不是这次唤醒的线程就有问题了。

条件变量中`wait`释放锁并阻塞，是原子的。

描述等待条件时，使用while相比使用if总是一个更好的主意。使用while总是正确的，然而使用if某些情况下是错误的。

如果没有描述状态的共享变量的话，将有可能会出现lost wakeup问题。也就是说在唤醒者先执行的情况下，需要将这一次wakeup放到一个缓冲区中。也正因为需要这样的共享变量，才需要引入互斥锁和条件变量一起使用。这样的话感觉就是管程啊...？先不想那么多了。

关于signal和wait与锁的关系：wait的语义决定在wait的时候必须拿着锁，而看起来signal没有这样的要求。也许在某些情况下，signal的时候不持有锁是正确的，但是一般情况下应该这样做。因为一般意义上来说，signal和wait都需要对线程间的共享状态进行读写，这样做的时候通常是需要互斥锁进行保护的。

signal的语义：对于Mesa语义来说，虽然唤醒了一个线程，但是对于被唤醒的线程来说，共享状态可能已经发生改变，因此需要重新确认（当然这个时候一定是拿着锁的），因此就需要while循环了。相反，Hoare语义能够确保在线程被唤醒之后能够立即被执行（和Hensen一样至少都是保证唤醒的线程一定下一个进入临界区）。

条件变量的应用：一个简单应用，还有我后写的多线程同步屏障问题

信号量的应用：读者写者问题（或者叫多生产者单消费者问题）。

两个同步互斥实例问题：哲学家问题和读者-写者问题。读者还是写者优先看具体实现吧，我们这里应该不太需要涉及。

信号量为什么不经常和自旋锁绑定呢？因为线程之间共享的好像只有信号量本身，而这个OS（或者其实现者）已经保证其原子性了。

# 信号量

一个值，原子操作，值的含义，结合阻塞唤醒机制

# 条件变量

和信号量的不同在于，条件变量是在管程中，天生和锁融合的。

如果信号量想这样做的话，先上锁..?这样就死锁了。而且，在没有实际操作共享资源的时候就拿锁，是非常浪费的行为。即使这样做了，在阻塞的时候也必须先把锁交出去（我劝你善良.jpg。

入口队列（其实就是一个就绪队列），条件变量阻塞队列以及紧急等待队列（用来应对Hoare语义，因而并非必需的）

需要互斥锁->死锁->睡眠的时候把锁交出去；如果用信号量，首先是信号量的适用面比较窄（其实这个例子本身的话用信号量还是能够解决的，不过并不是所有的同步条件都适合用信号量来描述），

忙等改造...

首先是介绍管程，然后是用我们的语言和已有的互斥原语来模拟管程，其中就包括条件变量。

管程的思想就是首先有一把大锁保证同一时间只有一个活跃线程（那么这个是否是由于与等待和唤醒有关的共享资源呢，可能吧），然后就是要支持等待和唤醒操作。

条件变量的使用和实现，唤醒信号的不同语义和其中哪一个有关？

先回顾一下不同语义，假设T1唤醒T2。那么Hoare应该是T2优先（因此需要紧急唤醒），T1转交锁；而Hensen应该是T1优先，最后在离开的时候转交锁；Mesa的话优先级T1>T2，但是并不会转交锁。

| 语义   | 使用wait  | 实现wait | 使用signal | 实现signal |
| ------ | --------- | -------- | ---------- | ---------- |
| Hoare  | 可以if    | -        |            | 锁的转交   |
| Hensen | 可以if    | -        |            | 锁的转交   |
| Mesa   | 必须while | -        |            | 锁释放     |



# 并发中的各种问题

死锁（这个时候把哲学家问题放进去）、锁的粒度还有优先级反转问题应该介绍。

活锁似乎主要来自于不适当的互相谦让（其他的说法比如是状态的不断转换），比如已经获得了一部分锁，在进入临界区之前又把锁交出去。[活锁相关链接](https://www.baeldung.com/java-deadlock-livelock)

顺带，这里是[课程大纲](https://github.com/LearningOS/os-lectures/blob/master/os-course-outline.md)，需要参考其中的内容对书进行修改。

## 并发中的其他问题

读ostep的thread-bugs一节。

主要的两种其他问题（占据97%左右）：原子性缺失和顺序缺失。原子性缺失在互斥锁一节应该已经有相当详细的介绍了。顺序缺失感觉主要是之前提到的条件同步问题吧。这两种bug只需注意到操作系统的调度影响看起来就能避免了。但是还有一些少数的bug需要对程序的行为有相当的理解才能够解决。

## 死锁

读ostep的thread-bugs一节。

出现原因：T1持有锁L1等待锁L2；T2持有锁L2等待锁L1（在操作系统调度下可能发生）。这里有一张看起来不错的图（循环等待）。

死锁来源：系统各模块之间复杂的依赖关系；数据封装，接口没有显式指出锁的使用方式而导致不当使用。

出现死锁的四个必要条件：互斥访问；线程在持有部分资源的情况下等待其他资源；不允许抢占，一旦线程已经持有了资源就不能被其他线程抢走；循环等待：存在一个线程的有向环，使得其中每个线程都持有一个或多个资源，这些资源被环上的下一个线程所等待。

死锁预防（如何阻断死锁的必要条件）：

* 循环等待：不同锁的获取顺序保证全序或者偏序（这个死锁必要条件的等价性是否有必要说明？），需要对代码有着深入理解。一种简单的全序构建方法是：总是按照锁的地址升序获取，但是适用范围很窄。
* 持有-等待：使用另一个锁保证能够原子的获取到所有的锁（然而这和全局上一把大锁也没区别了吧，好像有些不同？）。
* 不允许抢占：比如说使用`trylock`这种接口，当锁已经被持有的时候返回失败。一种使用方法可以是：获取L1之后，如果L2已经被获取，那么释放L1放弃这次访问。这样，即使另一个线程以相反的顺序进行访问（也使用`trylock`），也不会导致死锁。然而，现在有可能导致活锁。我们也有一些解决方案。无论如何，使用`trylock`的这种方式会加剧数据封装的问题，更容易导致错误（需要更加精确的进行资源回退）。注意这里其实是一种cooperation而非non-preemption。
* 互斥：使用无锁数据结构。例子：链表append操作。

通过调度*避免*死锁：将互相冲突的线程放在同个CPU上串行处理，**串行化**，比较保守，效率不高；银行家算法也属于通过调度避免的一个例子，但这类算法被批评适用范围较小，需要全局信息，仅在嵌入式环境下比较合适

死锁检测和恢复：据说在数据库领域比较常用。周期性检测死锁，检测到了直接重启。
