首先尝试把已有的结果跑起来...发现`WSL`好像不太行，又或者是闻11不太行...换成虚拟机之后稍微稳定一点，没那么容易卡死了。

先看一下第九章已有的文档，不然的话还是脑瓜子嗡嗡的。文档里面的是跟`virtio-gpu`有关的部分，之前看过了。

如果在`main.rs`里面打开`create_desktop`的话，就能展示出一个桌面，桌面上有所有的应用，还有一个空白的`demo.txt`窗口，效果看起来还是非常好的...

## GUI 模块

那么我们先来看一下`gui`模块吧。这里是基于`embedded_graphics`库开发的，是一个嵌入式2D图形库，[这里](https://docs.rs/embedded-graphics/latest/embedded_graphics/examples/index.html)有很多例子。

在`mod.rs`里面定义了一个`Component`trait，有三个方法：`paint`,`add`和`bound`。从`add`的接口大概可以看出这些`Component`会被组织成一个树形结构。`paint`的话应该就是在屏幕上绘制；`bound`指出当前`Component`在屏幕上的边界，于是应该默认形状是一个矩形？`bound`返回值是从`embedded_graphics`导出的`Point`和`Size`，都是一个32位整数的二元组。

有这么几个子模块：

* 基础图形模块`graphics`，后面的模块都用到它

* 按钮`button`
* 图标`icon`
* 图片`image`
* 面板`panel`
* 终端`terminal`

### graphics

根据观察，库里面的2D坐标系统应该是先x后y，原点为左上角，x向右为正，y向下为正。

所有组件的绘制都依赖于`Graphics`类，定义如下：

```rust
#[derive(Clone)]
pub struct Graphics {
    pub size: Size,
    pub point: Point,
    pub drv: Arc<dyn GPUDevice>, // GPU 设备
}
```

其关键在于为它实现`DrawTarget`trait:

```rust
impl DrawTarget for Graphics {
    type Color = Rgb888;

    type Error = core::convert::Infallible;

    fn draw_iter<I>(&mut self, pixels: I) -> Result<(), Self::Error>
    where
        I: IntoIterator<Item = embedded_graphics::Pixel<Self::Color>>,
    {
        // 从 GPU 设备获取 framebuffer，应该是通过 MMIO 直接写入到屏幕缓存？
        let fb = self.drv.getfreambuffer();

        pixels.into_iter().for_each(|px| {// 每个 px 都是一个像素，类型定义尚不清楚
            let idx = ((self.point.y + px.0.y) * VIRTGPU_XRES as i32 + self.point.x + px.0.x) as usize * 4;
            // 从 idx 的计算方式很明显可以看出 framebuffer 是从上到下逐行扫描，行内从左到右
            // 每个像素点应该是rgba四个字节，不过我们使用的Rgb888没有a这一项，因此只写3个字节
            // 而 px.0.x 和 px.0.y 是组件中的局部坐标，px.1表示该像素点的颜色
            if idx + 2 >= fb.len() {
                return;
            }
            fb[idx] = px.1.b();
            fb[idx + 1] = px.1.g();
            fb[idx + 2] = px.1.r();
        });
        self.drv.flush();
        Ok(())
    }
}
```

注意`Graphics`有`Size`和`Point`两个参数，在其被传入`draw`进行绘制的时候，每个像素的位置都会加上`Point`的偏移。目前没看出`Size`有什么用。

至于屏幕的大小则是在``board.rs``里面硬编码，目前是`1280x800`。

### 图片 image

说是图片，确实也就是一张图片..

核心就在最后绘制图片的一步：

```rust
// 其中 point 表示屏幕上的绝对坐标，而 Graphics 里面可能是相对坐标
// 如果是挂在其他组件下面的话可能需要重新计算，目前好像没用
// Image 来自 embedded_graphics
// 绘制的时候传入的参数为上面的 Graphics
Image::new(&bmp, point).draw(&mut inner.graphic);
```

### 按钮 button

看起来就是一行文字。直接看绘制：

```rust
Text::with_alignment(
    text.as_str(),
    inner.graphic.bounding_box().center(),
    MonoTextStyle::new(&FONT_10X20, Rgb888::BLACK),
    Alignment::Center,
)
.draw(&mut inner.graphic);
```

### 图标 icon

这个不只是一个单纯的`paint`，而是直接一个循环画出满屏的文件图标和文件名。

### 面板 panel

类似于一个组件管理器，所有东西都挂在下面。绘制的时候首先绘制一层白色背景，然后依次绘制挂着的所有组件。

### 终端terminal

terminal的话，rcore-os里面有一个更成熟的：[embedded-term](https://github.com/rcore-os/embedded-term)

当前这个terminal的话，有一个text和title，还有一堆挂在下面的组件，`paint`的时候就依次将它们绘制一下。

### 绘制总函数

来看`syscall`里面的`create_desktop`函数。

`DESKTOP`自身是一个Panel，然后里面先加上背景图Image再加上图标Icon，然后绘制`DESKTOP`。

terminal就是那个标题为`demo.txt`的大白板...

感觉代码写的很乱...要大修。

## 输入

我们看到有一个叫做`VirtIOInput`的东西，似乎能同时接收鼠标和键盘的输入，使用一个`virtio_input_decoder`的库对输入进行解析。

那么这就有两个问题：

1. 键盘输入到底是走这个input还是走串口？QEMU应该如何配置？
2. 鼠标在屏幕上移动的机制是如何实现的？

才发现键盘和鼠标是两个设备，分别占用MMIO区域VIRTIO5和VIRTIO6。

>  VIRTIO设备编号分配好像是按照QEMU配置里面的顺序？是否如此呢？
>
> 块设备`0x10008000`；串口`0x10000000`；GPU`0x10007000`；键盘`0x10005000`；鼠标`0x10006000`
>
> 这个很明显和`run.sh`里面QEMU的配置不同。所以说看起来的话应该是硬编码在fdt里面的？
>
> 值得注意的事情是：增加/删除某设备是否会影响到其他设备的槽位呢？
>
> fdt上面只是`0x10001000`到`0x10008000`有8个`virtio_mmio`设备，但是并没有指明哪个是哪个，所以正确的做法大概还是扫描fdt，然后把设备初始化之后加入到设备管理器。好像也？不是很麻烦？？？但是先不管这个了吧。
>
> 不过这个还是有影响的，我们应该在处理ch9之前把k210的支持去掉。

然后发现`demo.txt`上面是能打字的...（参考输入解析那里的逻辑）但是按两下键盘才出一个字母，然后打了8个a就卡死了。这个也挺奇怪的。另外，`println`还是走串口的，能看到之前的那些信息。

鼠标移动的机制是在初始化GPU的时候就把鼠标指针的图片传进去，调用一个`setup_cursor`。而后在鼠标位置改变的时候好像就能自动重绘，至少我没看到鼠标事件的handler，这也太方便了吧。

关于键盘的问题：根据目前的观察，应该是tutorial的终端界面在上面的时候走的就是串口；图形界面在上面的时候走的就是virtio。这感觉也有点逆天。

## 2022/12/14

明天改写一下第九章的代码。首先是引入设备树进行外设探测和初始化；然后是让生成的东西再好看一些。修复一些小bug。

## 第九章原文档阅读

这样才能有更好的整体规划。

UART属于QEMU模拟出来的真实物理设备，而VIRTIO系列外设则属于虚拟设备。

CPU连接的外设的发展过程：从类似单片机上的GPIO进行简单控制；后来发展到使用独立的I/O控制器控制多个设备，特点是CPU需要对端口/设备寄存器进行轮询，使得CPU使用效率低；再后来出现了总线连接多个外设，连接在同一个总线上的外设需要遵守相同的I/O时序，常见的总线包括I2C，PCI总线等；再后来I/O控制器拓展出了中断机制（一个问题：PIO是什么？）；高吞吐量设备，即绕开CPU直接与内存进行数据交互，如DMA等。

CPU与设备的交互方式有三种：Programmed I/O（进一步分成MMIO和PMIO）；Interrupt-based I/O还有DMA。但有些时候这些交互方式是融合起来的。比如说VIRTIO块设备等。DMA到底是一种交互方式，还是一种特定的控制器？

### I/O设备抽象

**I/O设备接口抽象**：从I/O设备自身需要考虑对外提供的接口和对内如何物理实现；从交互的角度来看可以分成状态、命令、数据。而交互方式有两种：基于轮询或是基于中断。	

**I/O设备统一抽象**：

* 基于文件

  仅凭`open/close/read/write`不足以涵盖多种外设的功能。因此引入`ioctl`系统调用实现对外设的灵活控制，传入的参数分别是要操作的外设的文件描述符和特定于该外设的一个请求码。问题是太灵活了，请求码无规律可循。而且看来文件抽象本是用于结构化的持久化存储，在此基础上拓展空间有限。

* 基于流

* 基于virtio：从虚拟机接口到真实物理外设的通用接口

### I/O执行模型

比如说`read`系统调用，在执行的时候流程上分为两个阶段：

1. 等待数据准备好

2. 将数据从内核拷贝到用户进程中

5种I/O模型在这两个阶段中会有不同的表现：阻塞I/O，非阻塞I/O，I/O复用，信号驱动I/O（数据准备好之后发送信号给进程，进程的handler被调用再通过系统调用读取数据）和异步I/O。

两个概念：阻塞/非阻塞强调用户进程执行系统调用后是否会被阻塞；同步/异步关注消息通信机制，即进程和内核（包含驱动）是否步调一致，是否需要协调。

同步和异步的区别在于：第二阶段是否需要进程参与。对于异步I/O来说，只需在I/O请求的时候提供待交互的I/O设备和缓冲区。等到信号发过来的时候I/O请求就已完成，缓冲区已包含待读取的数据。

### 个人意见之I/O设备

I/O复用似乎是说一个进程同时与多个设备打交道。

同步带来流程上的简单清晰、透明，异步带来更好的性能和并发度，然而同时带来更大的复杂性。

阻塞是否可以理解为必须等到I/O请求完成再返回，而非阻塞意思是无论I/O请求是否完成都立即返回。同步似乎意味着等待，即快的一方要等待慢的一方；异步意味着不必等待，于是快的一方可以选择先去做别的事情，并定期查看慢的一方是否完成，或者慢的一方完成后以某种方式通知快的一方。在这个时候，我们似乎默认了两方是独立的，就好像CPU和外设之间从物理上来说是独立的。进程和内核之间的关系便可以假想为CPU和外设之间的关系，它们之间的接口是系统调用。

我们是否需要纠结同步/异步这个概念呢？同步/阻塞：放弃CPU使用权直到I/O请求完成（或者说I/O请求的优先级高于进程执行）；异步/非阻塞：不会因为I/O请求而放弃CPU使用权。这好像是一种挺好的说法。而之前的异步系统调用也是在返回的时候功能未必完成。

阻塞+多线程 versus 异步+单线程？

这个话题过于宏大了，后面再慢慢想。

### 涉及到的其他内容

* 驱动程序概述：大概要完成的功能
* 硬件系统架构
  * 设备树（由RustSBI固件解析并传递到内核，内核据此进行设备探测和初始化）
  * 平台级中断控制器PLIC
  * 串口驱动（串口这里如何处理中断，以及和进程之间的关系文档这里面还不完善）
* virtio总体架构、块设备和GPU的接口详细分析

## 2022/12/18

最近稍微实现了一下更有交互性的玩法，然后运行一些比较复杂的应用比如`eisenberg`或者`usertests`就比较容易卡死。我分析原因应该是不应该在时钟中断的时候做太多事情，比如说不应该进行任何渲染行为。话说起来渲染也太慢了，比想象中要慢很多，即使每次并不将当前的frame buffer清空也还是慢。主要还是逐像素渲染比较慢，BlogOS里面是VGA Text模式的。现有的Graphics的实现，每个像素需要拷贝3字节。每个字母可能有200个像素

时钟中断处理时间过长的结果：可能会使得控制不精准，但是应该不至于直接卡死吧...总之直接卡死的原因未知。

如何避免处理时间过长：在时钟中断处理的时候仅进行记录，将相关的处理流程放到应用或者一个内核线程中，内核线程更方便一些。也搞一个类似事件循环的东西吧。在循环开头接收一下绘制上一帧的时候接收到的事件，根据这些事件绘制下一帧。然后在中断的时候我们只是将相关事件丢到一个队列中，或是采用更快的方式。这样的话，甚至计算帧数也成为可能了。原先那种锁帧然后帧数实际上达不到过于坑爹了。但是实际上不太想弄内核线程...有点太麻烦。

很麻烦的一件事情是内核线程如何调度，如何和现有的调度器结合起来？现有的很多接口都是假定了我们是从某个应用Trap到内核里面的，所以会使用`current`之类的接口。而且原先的RR调度肯定不行，如果有很多任务，轮到这个内核线程可能已经过去很多个时间片了。为了更好的响应效果，我们需要优先级调度了。

## 2022/12/19

最后摆烂弄了一个十分简单的效果（说不定还不如之前？）

准备开始写文档！（才开始？）

首先比较一下ch8和ch9之间的差距：

* `BlockDevice`trait（包括`easy-fs`，`easy-fs-fuse`还有`os`）都新增了一个`handle_irq`函数
* qemu配置中新增了RAM大小设置和若干设备，新增了`make fdt`命令
* `board.rs`中新增了更多MMIO区间；新增了字符设备实现`CharDeviceImpl`；新增了设备初始化接口`device_init`；新增了中断处理函数`irq_handler`；`config.rs`中调整了内核堆大小和RAM大小；
* `console.rs`底层实现由SBI转为自己实现的串口驱动；
* `virtio_blk.rs`提供了基于中断的阻塞式访问（要点：配合`CondVar`的`wait_no_sched`接口），同时VIRTIO header的MMIO位置居然也有所变化，看来我们可能还是基于设备树比较好；
* `bus/virtio.rs`新增了所有Virtio设备通用的底层内存管理接口（为什么ch8的时候没有：因为那个时候只有一个块设备）
* `chardev/mod.rs`和`chardev/ns16550a.rs`是我们的串口驱动
* `gpu/mod.rs`是我们的GPU驱动，核心在于获取frame buffer
* `input/mod.rs`提供了鼠标/键盘设备驱动，在中断处理时提供对屏幕画面的简单控制，然而...
* `drivers/mod.rs`新增了大量子模块
* `plic.rs`新增了PLIC驱动
* `fs/inode.rs`,`fs/pipe.rs`,`mm/frame_allocator.rs`,`mm/memory_set.rs`,`sync/condvar.rs`,`sync/mod.rs`,`sync/semaphore.rs`,`task/id.rs`,`task/manager.rs`,`task/process.rs`,`task/processor.rs`,`task/task.rs`,`timer.rs`使用新同步原语`UPIntrFreeCell`
* `fs/stdio.rs`底层使用自己的串口驱动读入
* `gui/graphics.rs`提供`embedded_graphics`所需的接口，`gui/paint.rs`作为上层应用
* `lang_item.rs`里面有个`shutdown(255)`，可能得看一下前面的章节（相关：`sbi.rs`）
* `main.rs`里面的逻辑改变
* `sync/condvar.rs`更改成`wait_no_sched`和`wait_with_mutex`接口，需要看一下前面章节（相关系统调用`sys_condvar_wait`）
* `sync/up.rs`提供新同步原语`UPIntrFreeCell`
* `task/manager.rs`以及`task/mod.rs`,`timer.rs`关于[issue60](https://github.com/rcore-os/rCore-Tutorial-v3/issues/60)在ch8上的改动似乎并没有加入到ch9上面，因此我们又回想起了这个陈年bug
* `trap/mod.rs`以及`trap/trap.S`中若干改动
* 用户态改动...

关于阻塞的地方有些是和ch8有关的，所以那里的文档要先看一下。
