## 10/08/22

当ThreadInner调用change_state的时候：

```rust
/// Change state and update signal.
fn change_state(&mut self, state: ThreadState, base: &KObjectBase) {
    self.state = state;
    match self.state() {
        ThreadState::Dead => base.signal_change(
            Signal::THREAD_RUNNING | Signal::THREAD_SUSPENDED,
            Signal::THREAD_TERMINATED,
        ),
        ThreadState::New | ThreadState::Dying => base.signal_clear(
            Signal::THREAD_RUNNING | Signal::THREAD_SUSPENDED | Signal::THREAD_TERMINATED,
        ),
        ThreadState::Suspended => base.signal_change(
            Signal::THREAD_RUNNING | Signal::THREAD_TERMINATED,
            Signal::THREAD_SUSPENDED,
        ),
        _ => base.signal_change(
            Signal::THREAD_TERMINATED | Signal::THREAD_SUSPENDED,
            Signal::THREAD_RUNNING,
        ),
    }
}
```

这会clear掉RUNNING和SUSPENDED，并set TERMINATED。不过这里是线程信号，而我们需要重点观察的是进程信号。

在run_user退出之后进入了`Process::remove_thread`，进而进入了`Process::terminate`，里面会调用`signal_set`，也会触发signal_callback。所以问题就变成`Process::remove_thread`是谁调用的？看了一下，这个也是`Thread::drop`调用`Thread::terminate`里面再调用的，见：

```rust
/// Terminate the current running thread.
fn terminate(&self) {
    let mut inner = self.inner.lock();
    self.exceptionate.shutdown();
    inner.change_state(ThreadState::Dead, &self.base);
    /// here
    self.proc().remove_thread(self.base.id);
}
```

好的，那现在我们可以回到我们的实现看看哪个环节出现了问题。这是原版zCore的输出：

```
[  4.101675 INFO  0 0:0 linux_syscall::task] exit_group: code=0
[  4.102565 INFO  0 0:0 zircon_object::task::process] into Process::exit
[  4.103524 INFO  0 0:0 zircon_object::task::thread] into Thread::stop
[  4.104619 INFO  0 0:0 linux_syscall] <= Err(ENOSYS)
[  4.105774 INFO  0 0:0 zcore_loader::linux] exit run_user
[  4.107790 INFO  0 0:0 zircon_object::task::process] into Process::remove_thread
[  4.109305 INFO  0 0:0 zircon_object::task::process] into Process::terminate
[  4.110557 INFO  0 0:0 linux_object::process] Received signal: SIGNALED | TASK_TERMINATED | JOB_TERMINATED | PROCESS_TERMINATED | THREAD_TERMINATED | VMO_ZERO_CHILDREN
[  4.112914 INFO  0 0:0 linux_syscall] <= Ok(1045)
```

这是我的输出：

```
[m[37m[  4.489577 [92mINFO [m [37m1 0:0 linux_syscall::task][m [32mexit_group: code=0[m
[m[37m[  4.490260 [92mINFO [m [37m1 0:0 zircon_object::task::process][m [32minto Process::exit[m
[m[37m[  4.491048 [92mINFO [m [37m1 0:0 linux_syscall][m [32m<= Err(ENOSYS)[m
[m[37m[  4.491670 [92mINFO [m [37m1 0:0 zircon_object::task::thread][m [32minto Thread::terminate[m
[m[37m[  4.492437 [92mINFO [m [37m1 0:0 zircon_object::task::process][m [32minto Process::remove_thread[m
[m[37m[  4.493248 [92mINFO [m [37m1 0:0 zircon_object::task::process][m [32minto Process::terminate[m
[m[37m[  4.494027 [92mINFO [m [37m1 0:0 linux_syscall::async_syscall][m [32mtask 183 dropped[m
```

可以看到，在`Process::exit`中并没有调用`Thread::stop`。这是`Process::exit`的代码，我的实现似乎在pt0之前就return了，而原版zCore可以通过pt0和pt1到达后面的`thread.kill`。所以这个看起来非常奇怪...

```rust
/// Exit current process with `retcode`.
/// The process do not terminate immediately when exited.
/// It will terminate after all its child threads are terminated.
pub fn exit(&self, retcode: i64) {
    info!("into Process::exit");
    let mut inner = self.inner.lock();
    if let Status::Exited(_) = inner.status {
        return;
    }
    info!("Process::exit pt0");
    inner.status = Status::Exited(retcode);
    if inner.threads.is_empty() {
        inner.handles.clear();
        drop(inner);
        self.terminate();
        return;
    }
    info!("Process::exit pt1");
    for thread in inner.threads.iter() {
        thread.kill();
    }
    inner.handles.clear();
}
```

看起来原因是每次执行完一个syscall都会调用`CurrentThread::drop`，进而触发`Thread::terminate`到`Process::remove_thread`到`Process::terminate`，可能这个时候进程状态已经被改成Exited了。这个显然是不对的，但是好像又不太能`mem::forget`，可能会造成堆内存泄露。目前的做法是把run_user参数CurrentThread改成`Arc<CurrentThread>`，目前看起来的流程能和原版zCore对上了。

接下来，我们就看看vmexit里面的TIMER和EXT_INTR是怎么回事。其实我怀疑这两个都是时钟中断...?从一些数据来看，EXT_INTR始终比TIMER要多一点，EXT_INTR的平均耗时为2.4us，而TIMER的平均耗时则是0.7us左右，这说明这两个不是一个东西？

目前时钟中断频率为1000Hz，调整为2000Hz看看二者的比值是否发生变化。2000Hz，在8.43s之内，发现16966次TIMER和8320次EXT_INTR，看起来TIMER显然是更为接近的。再试试3000Hz，8.74s之内，发现13098次TIMER和18925次EXT_INTR，有点奇怪，重复实验；9.02s内，13200次TIMER和19484次EXT_INTR；9.05s之内，发现32376次EXT_INTR；9.26s内，发现32057次EXT_INTR。

暂停一下，在Intel文档vol3 25.2里面倒是找到了这两个触发vmexit的相关描述。尝试在qemu配置里面加上`-vmx-intr-exit`试试。这个配置没用。

在不使用perf的情况下，时钟中断设置为100Hz，发现大概每0.024s（即实际上只有40Hz左右）打印一次中断相关语句，在截取的片段内只有3次来自于handle_user_trap，而527次都来自kernel_hal里面的trap_handler，vector都是0xf1即`X86_INT_APIC_TIMER`。如果使用perf，时钟中断100Hz，还是大概0.025s打印一次中断语句，这回只有1个vector=0xf1，677次Intr: 0xf1，还有3次Intr: 0x20。根据perf的数据来看，共有940次TIMER（两个CPU各470次）还有6594次EXT_INTR（cpu0/1分别4958/1636次）。从打印的log来看，开启perf之后确实差不多有470行时钟中断log，但是全部来自vcpu 0，vcpu1上确实不应该有log，因为上面并没打开中断。

所以目前结论只能是，真的搞不懂EXT_INTR是哪来的，至少从log上完全看不出来。